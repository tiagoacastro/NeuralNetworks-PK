{"nbformat":4,"nbformat_minor":0,"metadata":{"celltoolbar":"Create Assignment","kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Erasmus_NeuralNetworks_16 Tensorflow and Keras for MNIST.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-0b2104075deb75b5","locked":true,"schema_version":1,"solution":false},"id":"2qIZ9pPpFY3E"},"source":["# Erasmus Neural Networks\n","http://michalbereta.pl/nn\n","## TensorFlow and Keras for MNIST\n","\n","\n","Keras: https://keras.io/\n","\n","TensorFlow: https://www.tensorflow.org/\n","\n","### Note !\n","\n","Training exemplary neural networks in this notebook is computationally demanding. In case of problems, use the attached pretrained models  (files \\*.hdf5)."]},{"cell_type":"markdown","metadata":{"id":"LrsOQOAPFY3I"},"source":["### Check your configuration"]},{"cell_type":"code","metadata":{"id":"TEDTwpURFY3K"},"source":["import tensorflow as tf\n","import keras as krs\n","\n","print(tf.__version__)\n","print(krs.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_1gkDZOYFY3P"},"source":["## MNIST database\n","\n","\n","The MNIST database contains a training set consisting of 60,000 examples of scans of hand-written numbers from 0 to 9 (classification problem with 10 classes).\n","\n","The test set contains 10,000 examples.\n","\n","Each image has a size of 28x28 pixels. They constitute 28 * 28 = 784 inputs to the network.\n","\n","In machine learning and image recognition community, the MNIST database serves as a kind of `Hello world` problem.\n","\n","\n","Read more about the MNIST database:\n","\n","http://yann.lecun.com/exdb/mnist/\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mWGzVAoWFY3R"},"source":["## Getting MNIST\n","\n","The MNIST database can be downloaded in a binary version directly from the website:\n","\n","http://yann.lecun.com/exdb/mnist/\n","\n","\n","In the form of csv files , the MNIST database is available on the website:\n","\n","https://pjreddie.com/projects/mnist-in-csv/\n","\n","\n","The most convenient way, however, is to use the MNIST database import using the Keras library. At the first import, this database will be downloaded automatically (about 12MB). It will be placed in the directory `~ / .keras / datasets / mnist.pkl.gz`.\n","\n","Below is an example code that reads training and test data, and displays several sample images."]},{"cell_type":"code","metadata":{"id":"z2rSj8HiFY3S"},"source":["%matplotlib inline\n","import tensorflow as tf\n","import keras as krs\n","import numpy as np\n","\n","from keras.datasets import mnist\n","import matplotlib.pyplot as plt\n","\n","(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n","print('xtrain.shape',xtrain.shape)\n","print('ytrain.shape',ytrain.shape)\n","print('xtest.shape',xtest.shape)\n","print('ytest.shape',ytest.shape)\n","\n","#wyswietlenie pierwszego przykladu\n","plt.imshow(xtest[0,:,:], cmap=plt.get_cmap('gray'))\n","\n","#Wyswietlenie kilku pierwszych przykladow\n","rows = 8\n","cols = 10\n","counter = 0\n","\n","images = None\n","\n","for i in range(rows):\n","    current_row = None\n","    for j in range(cols):\n","        im = xtest[counter,:,:]\n","        counter = counter + 1\n","        if current_row is None:\n","            current_row = im\n","        else:\n","            current_row = np.hstack((current_row, im))\n","    if images is None:\n","        images = current_row\n","    else:\n","        images = np.vstack((images, current_row))\n","        \n","plt.figure()\n","plt.imshow(images, cmap=plt.get_cmap('gray'))\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IN22ymxCFY3X"},"source":["## MLP network with one layer hidden in the MNIST problem\n","\n","We will check how the MNIST problem will be dealt with by the MLP neural network with one hidden layer."]},{"cell_type":"markdown","metadata":{"id":"s3TuOezvFY3Y"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"wBOofSzrFY3a"},"source":["import tensorflow as tf\n","import numpy\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.models import load_model\n","from keras.utils import np_utils\n","\n","#If necessary, change the current catalog\n","#import os\n","#path = '.'\n","#os.chdir(path)\n","\n","print(tf.__version__)\n","print(keras.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CkMXBsZgFY3f"},"source":["### Loading data\n","\n","Please note that the data is stored as a 3-dimensional tensor."]},{"cell_type":"code","metadata":{"id":"OqqJCv6YFY3g"},"source":["(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n","print('xtrain.shape',xtrain.shape)\n","print('ytrain.shape',ytrain.shape)\n","print('xtest.shape',xtest.shape)\n","print('ytest.shape',ytest.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UawhLG2qFY3l"},"source":["### Seed initialization (to allow for repeatability of calculations)"]},{"cell_type":"code","metadata":{"id":"Y_KjVRosFY3m","executionInfo":{"status":"ok","timestamp":1610580775918,"user_tz":-60,"elapsed":583,"user":{"displayName":"Michał Bereta","photoUrl":"","userId":"16966304629895689983"}}},"source":["seed = 12345\n","numpy.random.seed(seed)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ci4elsUfFY3s"},"source":["### Preparation of input data\n","\n","The original 28x28 pixel images will be fed into the network input layer as vectors with a length of 784.\n","\n","In addition, the normalization of pixel values from the interval [0.255] into interval [0,1] will have a positive impact on the network learning process.\n"]},{"cell_type":"code","metadata":{"id":"Knf0b71HFY3t"},"source":["inputs_num = xtrain.shape[1] * xtrain.shape[2] #number of pixels = number of network inputs\n","xtrain = xtrain.reshape(xtrain.shape[0], inputs_num).astype('float32')\n","xtest = xtest.reshape(xtest.shape[0], inputs_num).astype('float32')\n","\n","# normalize inputs from 0-255 to 0-1\n","xtrain = xtrain / 255\n","xtest = xtest / 255\n","\n","print(xtrain.shape)\n","print(xtest.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mwY_CtPiFY3z"},"source":["### Coding of class information (requested responses from 10 output neurons)"]},{"cell_type":"code","metadata":{"id":"z5scKmnRFY30"},"source":["ytrain = np_utils.to_categorical(ytrain)\n","ytest = np_utils.to_categorical(ytest)\n","num_classes = ytest.shape[1]\n","print(ytest.shape)\n","print(ytest[0,:])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VEuhdBx5FY35"},"source":["### Defining and compiling the model"]},{"cell_type":"code","metadata":{"id":"-tDWeDOwFY37","executionInfo":{"status":"ok","timestamp":1610580817213,"user_tz":-60,"elapsed":6938,"user":{"displayName":"Michał Bereta","photoUrl":"","userId":"16966304629895689983"}}},"source":["model = Sequential()\n","model.add(Dense(500, input_dim=inputs_num, kernel_initializer='normal', activation='relu'))\n","model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vXWhqCB9FY4A"},"source":["### Saving the best model to a file\n","\n","During the learning process, we can monitor selected metrics and save current network models to the file. This is useful for big problems, when network learning takes a very long time and loss of results in case of failure is an unpleasant experience.\n","\n","In the following example, we monitor the quality of the classification on the validation set and save the model to the file, as long as it is better than any earlier (i.e., from earlier epochs)."]},{"cell_type":"code","metadata":{"id":"5q-7cAr4FY4C","executionInfo":{"status":"ok","timestamp":1610580914989,"user_tz":-60,"elapsed":582,"user":{"displayName":"Michał Bereta","photoUrl":"","userId":"16966304629895689983"}}},"source":["logger = keras.callbacks.ModelCheckpoint('mnist_model_MLP.hdf5', monitor='val_accuracy', verbose=0, save_best_only=True)\n"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yq3W43QdFY4H"},"source":["model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=20, batch_size=200, verbose=2, callbacks=[logger])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PwpbcmWKFY4L"},"source":["### Evaluation of the final and best model"]},{"cell_type":"code","metadata":{"id":"gLXmccrqFY4N"},"source":["scores = model.evaluate(xtest, ytest, verbose=0)\n","print(\"Test error: %.2f%%\" % (100-scores[1]*100))\n","\n","#reading the best model from file\n","model2 = load_model('mnist_model_MLP.hdf5')\n","scores2 = model2.evaluate(xtest, ytest, batch_size=200)\n","print('network from file:')\n","print(\"Test error: %.2f%%\" % (100-scores2[1]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g7dot9GtFY4S"},"source":["## The best results for MNIST \n","\n","How does our result compare the the best ones?\n","\n","http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354"]},{"cell_type":"markdown","metadata":{"id":"FaYVdZwnFY4T"},"source":["## Convolutional networks\n","\n","Currently, some of the best models for image analysis are convolutional networks.\n","\n","The basis of their functioning are:\n","\n","- convolutional layers (sharing weights between neurons)\n","- MaxPooling layers (reduction of the dimensionality of the problem)\n","- ReLU type activation functions\n","- regularization, e.g. by the Dropout method\n","\n","A popular model is a convolutional network in which a number of convolutional layers with ReLU activation functions alternate with MaxPooling layers. After that one or more layers of the MLP type follows (the designation FC means' Fully Connected`).\n","\n","Often, there are layers implementing the Dropout type of regularization strategies, which are supposed to counteract the over-fitting of the model.\n","\n","The following pictures are from http://cs231n.github.io/convolutional-networks/\n","\n","![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"i_oeNYUgFY4V"},"source":["###  ReLU activation function\n","\n","https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\n","\n","![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"H9Y67jsZFY4W"},"source":["![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"ivZRQf-_FY4Y"},"source":["### Convolutional layers\n","\n","The convolutional layer is a set of filters (neurons) that scan all channels of the input image (three in the example below). Scanning means that the weights of the same neuron are used repeatedly, which reduces the number of neurons needed.\n","\n","The following example has two 3x3 filters, so the output of this convolutionary layer will be a new image with two channels (Output Volume).\n","\n"]},{"cell_type":"markdown","metadata":{"id":"N9fR5ug9FY4Z"},"source":["![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"DlKUqrWeFY4a"},"source":["![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"8tPaDmXdFY4c"},"source":["###  Max Pooling Layers\n","\n","The Max Pooling layers are designed to limit the dimensionality of data transferred to subsequent layers. From each selected area (eg 2x2 pixels), the maximum value is selected.\n","\n","Please note that pooling does not change the \"depth\" (number of channels).\n","\n","For example:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tME99y3MFY4d"},"source":["## Implementation of a simple convolutional network with Keras \n","\n","The designed network will have only one convolutional layer, followed by one hidden MLP layer. The output of the entire network will be another layer of the `softmax` type.\n"]},{"cell_type":"markdown","metadata":{"id":"WD7NB_ngFY4f"},"source":["### Imports and data loading"]},{"cell_type":"code","metadata":{"id":"TFCX5d17FY4g"},"source":["import tensorflow as tf\n","import numpy as np\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.models import load_model\n","from keras.utils import np_utils\n","\n","#import os\n","#path = '.'\n","#os.chdir(path)\n","\n","print(tf.__version__)\n","print(keras.__version__)\n","\n","(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n","print('xtrain.shape',xtrain.shape)\n","print('ytrain.shape',ytrain.shape)\n","print('xtest.shape',xtest.shape)\n","print('ytest.shape',ytest.shape)\n","\n","\n","seed = 12345\n","np.random.seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"odGmuz-uFY4k"},"source":["### Data preparation\n","\n","Please note that the network inputs are now images, not one-dimensional data. The convolutional layer expects data with the dimensions `(width, height, number of channels)`. In our MNIST example, the images are 28x28x1 (one channel, monochrome images).\n","\n","Please note the appropriate use of the `reshape` function.\n","\n","It is also possible to use the input data in the form `(number of channels, width, height)`"]},{"cell_type":"code","metadata":{"id":"hlucL1c5FY4m","executionInfo":{"status":"ok","timestamp":1610581218350,"user_tz":-60,"elapsed":580,"user":{"displayName":"Michał Bereta","photoUrl":"","userId":"16966304629895689983"}}},"source":["xtrain = xtrain.reshape(xtrain.shape[0], 28, 28, 1).astype('float32')\n","xtest = xtest.reshape(xtest.shape[0], 28, 28, 1).astype('float32')\n","\n","# normalize inputs from 0-255 to 0-1\n","xtrain = xtrain / 255\n","xtest = xtest / 255\n","\n","# one hot encode outputs\n","ytrain = np_utils.to_categorical(ytrain)\n","ytest = np_utils.to_categorical(ytest)\n","num_classes = ytest.shape[1]"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"adH73ZdWFY40"},"source":["### Defining and compiling the model\n","\n","The first layer is a convolution layer consisting of 32 filters with a size of 5x5 and a ReLU activation function.\n","\n","Please note that it was given directly\n","\n","`data_format='channel_last'`\n","\n","that is, data should have the format `(width, height, number of channels)`, in this example 28x28x1.\n","\n","The `Flatten` layer converts multidimensional data into one-dimensional, so that it can be used as another layer of MLP.\n","\n","The `Dropout (0.2)` layer means that each time 20% of random neurons will be excluded from network activity. This is to prevent the network from overfitting."]},{"cell_type":"code","metadata":{"id":"ZQz5BDuPFY42","executionInfo":{"status":"ok","timestamp":1610581273622,"user_tz":-60,"elapsed":578,"user":{"displayName":"Michał Bereta","photoUrl":"","userId":"16966304629895689983"}}},"source":["model = Sequential()\n","model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu', data_format='channels_last'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jN7NOpuLFY49"},"source":["### Training\n"]},{"cell_type":"code","metadata":{"id":"rORpALe0FY4-"},"source":["logger = keras.callbacks.ModelCheckpoint('mnist_model_CONV_SIMPLE.hdf5', monitor='val_accuracy', verbose=0, save_best_only=True)\n","\n","# Fit the model\n","model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=20, batch_size=200, verbose=2, callbacks=[logger])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mhLTA76OFY5C"},"source":["### Testing"]},{"cell_type":"code","metadata":{"id":"uHx74kU_FY5D"},"source":["scores = model.evaluate(xtest, ytest, verbose=0)\n","print(\"Test error: %.2f%%\" % (100-scores[1]*100))\n","\n","#Best model\n","model2 = load_model('mnist_model_CONV_SIMPLE.hdf5')\n","scores2 = model2.evaluate(xtest, ytest, batch_size=200)\n","print('The best network from file:')\n","print(\"Test error: %.2f%%\" % (100-scores2[1]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VCmIfT2yFY5H"},"source":["## A bigger convolutional network\n","\n","Compare previous results with the results of the following network. Read its architecture."]},{"cell_type":"code","metadata":{"id":"HxCXvVoqFY5I"},"source":["import tensorflow as tf\n","import numpy as np\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.models import load_model\n","from keras.utils import np_utils\n","\n","#import os\n","#path = '.'\n","#os.chdir(path)\n","\n","print(tf.__version__)\n","print(keras.__version__)\n","\n","(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n","print('xtrain.shape',xtrain.shape)\n","print('ytrain.shape',ytrain.shape)\n","print('xtest.shape',xtest.shape)\n","print('ytest.shape',ytest.shape)\n","\n","# fix random seed\n","seed = 12345\n","np.random.seed(seed)\n","\n","\n","xtrain = xtrain.reshape(xtrain.shape[0], 28, 28, 1).astype('float32')\n","xtest = xtest.reshape(xtest.shape[0], 28, 28, 1).astype('float32')\n","\n","# normalize inputs from 0-255 to 0-1\n","xtrain = xtrain / 255\n","xtest = xtest / 255\n","\n","# one hot encode outputs\n","ytrain = np_utils.to_categorical(ytrain)\n","ytest = np_utils.to_categorical(ytest)\n","num_classes = ytest.shape[1]\n","\n","# define model\n","model = Sequential()\n","model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(15, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","logger = keras.callbacks.ModelCheckpoint('mnist_model_CONV_BIGGER.hdf5', monitor='val_accuracy', verbose=0, save_best_only=True)\n","\n","# Fit the model\n","model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=20, batch_size=200, verbose=2, callbacks=[logger])\n","\n","# Final evaluation of the model\n","scores = model.evaluate(xtest, ytest, verbose=0)\n","print(\"Test error: %.2f%%\" % (100-scores[1]*100))\n","\n","#Best model\n","model2 = load_model('mnist_model_CONV_BIGGER.hdf5')\n","scores2 = model2.evaluate(xtest, ytest, batch_size=200)\n","print('The best network from the file:')\n","print(\"Test error: %.2f%%\" % (100-scores2[1]*100))\n","\n","print('end')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IDBslmj2FY5M"},"source":["## Comparing the models\n","\n","In case of problems with training, attached files\n","\n","- `_mnist_model_MLP.hdf5`\n","- `_mnist_model_CONV_SIMPLE.hdf5`\n","- `_mnist_model_CONV_BIGGER.hdf5`\n","\n","contain previously trained models.\n","\n","Use the following script to compare their actions. How far are these models from the best known?"]},{"cell_type":"code","metadata":{"id":"Q6tCgMhsFY5N"},"source":["import tensorflow as tf\n","import numpy as np\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.models import load_model\n","from keras.utils import np_utils\n","\n","#import os\n","#path = '.'\n","#os.chdir(path)\n","\n","print(tf.__version__)\n","print(keras.__version__)\n","\n","(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n","print('xtrain.shape',xtrain.shape)\n","print('ytrain.shape',ytrain.shape)\n","print('xtest.shape',xtest.shape)\n","print('ytest.shape',ytest.shape)\n","\n","xtrain = xtrain.reshape(xtrain.shape[0], 784).astype('float32')\n","xtest = xtest.reshape(xtest.shape[0], 784).astype('float32')\n","\n","# normalize inputs from 0-255 to 0-1\n","xtrain = xtrain / 255\n","xtest = xtest / 255\n","\n","# one hot encode outputs\n","ytrain = np_utils.to_categorical(ytrain)\n","ytest = np_utils.to_categorical(ytest)\n","\n","#Compare the networks\n","\n","#MLP\n","model = load_model('mnist_model_MLP.hdf5')\n","scores = model.evaluate(xtest, ytest, batch_size=200)\n","print(\"Test error (Model MLP): %.2f%%\" % (100-scores[1]*100))\n","\n","\n","xtrain = xtrain.reshape(xtrain.shape[0], 28, 28, 1).astype('float32')\n","xtest = xtest.reshape(xtest.shape[0], 28, 28, 1).astype('float32')\n","\n","#Smaller conv net\n","model = load_model('mnist_model_CONV_SIMPLE.hdf5')\n","scores = model.evaluate(xtest, ytest, batch_size=200)\n","print(\"Test error (Model CONV SIMPLE): %.2f%%\" % (100-scores[1]*100))\n","\n","#Bigger conv net\n","model = load_model('mnist_model_CONV_BIGGER.hdf5')\n","scores = model.evaluate(xtest, ytest, batch_size=200)\n","print(\"Test error (Model CONV BIGGER): %.2f%%\" % (100-scores[1]*100))\n","\n","print('end')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KxegXFlSFY5Q"},"source":["### Task 1\n","\n","- Prepare and train a convolutional neural network on CIFAR-10 database. \n","- Try different architectures of networks\n","- Compare and report the results\n"]},{"cell_type":"markdown","metadata":{"id":"4SlYaoCpFY5R"},"source":["#### YOUR DESCRIPTION AND COMMENTS"]},{"cell_type":"code","metadata":{"id":"95KzXO6mFY5S"},"source":["#YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VSL25QkVFY5W"},"source":["### Task 2\n","\n","NOT OBLIGATORY, DO IT ONLY IF YOU WANT!\n","\n","- Collect your own images from different categories and train different networks to recognize them.\n","\n","- Provide the best models saved in files together with a script to load and test them."]},{"cell_type":"markdown","metadata":{"id":"2J_osXqdFY5X"},"source":["#### YOUR DESCRIPTION AND COMMENTS"]},{"cell_type":"code","metadata":{"id":"uvPs4gPoFY5Y"},"source":["#YOUR CODE HERE"],"execution_count":null,"outputs":[]}]}